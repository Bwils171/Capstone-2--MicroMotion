{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import librosa as lib\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Audio\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split, RandomizedSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bwils\\anaconda3\\envs\\micromotion\\lib\\site-packages\\distributed\\node.py:151: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 53738 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Scheduler: \"tcp://127.0.0.1:53741\" processes: 3 cores: 6>,\n",
       " {0: <Nanny: tcp://127.0.0.1:53763, threads: 2>,\n",
       "  1: <Nanny: tcp://127.0.0.1:53760, threads: 2>,\n",
       "  2: <Nanny: tcp://127.0.0.1:53766, threads: 2>})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask import dataframe as dd\n",
    "import joblib\n",
    "from dask.distributed import Client, LocalCluster\n",
    "cluster = LocalCluster()\n",
    "client = Client(cluster)\n",
    "cluster.scheduler, cluster.workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = pd.read_pickle('DFs/model_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_time(model, algo,  X, y, split=5):\n",
    "    count=1\n",
    "    tscv = TimeSeriesSplit(n_splits=split)\n",
    "    scoretemp = {algo+'_MAE':[], algo+'_MSE':[], algo+'_MPE':[]}\n",
    "    for train_index, test_index in tscv.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        print(train_index[0], train_index[-1], test_index[0], test_index[-1])\n",
    "        with joblib.parallel_backend('dask'):\n",
    "            model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        #scoretemp[algo + '_R2'].append(r2_score(y_test, y_pred))\n",
    "        scoretemp[algo + '_MAE'].append(mean_absolute_error(y_test, y_pred))\n",
    "        scoretemp[algo + '_MSE'].append(mean_squared_error(y_test, y_pred))\n",
    "        scoretemp[algo + '_MPE'].append(mean_absolute_percentage_error(y_test, y_pred))\n",
    "        for i in scoretemp.keys():\n",
    "            print(i + ': '+ str(scoretemp[i][count-1]))\n",
    "        count+=1\n",
    "    scoretemp = pd.DataFrame(scoretemp)\n",
    "    return scoretemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Xy_prep(df, target, a=1, b=75):\n",
    "    df_1 = df.loc[df['PID'].between(a, b)]\n",
    "    drop_cols = ['PID', 'SID', 'target_5', 'target_10', 'target_20', 'X', 'Y','Z', 'segment']\n",
    "    df_1i = df_1.set_index('millisecond')\n",
    "    participants = b-a+1\n",
    "    cut_rows = int(target[-2:])*participants*10\n",
    "    X = df_1i.drop(columns=drop_cols).to_numpy()[:len(df)-cut_rows]\n",
    "    y = df_1i[target].to_numpy()[:len(df)-cut_rows]\n",
    "    cols = df_1i.drop(columns=drop_cols).columns\n",
    "    participants = b-a+1\n",
    "    \n",
    "    return X, y, cols, participants, cut_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([33.98706074, 32.36010032, 55.66196556, 58.29931355, 47.97609158,\n",
       "        19.84963942, 60.72575469, 81.12411828, 93.38701329, 38.67571592]),\n",
       " 'std_fit_time': array([ 3.11682946,  1.66133965, 10.6563258 , 14.97238165, 23.61278939,\n",
       "        19.85241766, 14.94537091,  2.34506947, 12.63848305, 29.47614101]),\n",
       " 'mean_score_time': array([0.1566596 , 0.20663223, 0.06368294, 0.06877284, 0.09560366,\n",
       "        0.13050227, 0.23616714, 0.09220009, 0.07615347, 0.07101202]),\n",
       " 'std_score_time': array([0.13659719, 0.11364672, 0.03217886, 0.03684385, 0.0780982 ,\n",
       "        0.10313131, 0.15325235, 0.04665735, 0.05219025, 0.04376756]),\n",
       " 'param_min_samples_split': masked_array(data=[0.6, 0.3, 0.3, 0.4, 0.7, 0.9, 0.1, 0.4, 0.6, 0.3],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[0.3, 0.5, 0.1, 0.2, 0.5, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_leaf_nodes': masked_array(data=[4, 10, 2, 2, 10, 2, 2, 10, 6, 6],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[5, 7, 7, 7, 3, 7, 7, 5, 1, 1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_criterion': masked_array(data=['mse', 'mae', 'mae', 'mse', 'mse', 'mse', 'mse', 'mae',\n",
       "                    'mae', 'mse'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'min_samples_split': 0.6,\n",
       "   'min_samples_leaf': 0.3,\n",
       "   'max_leaf_nodes': 4,\n",
       "   'max_depth': 5,\n",
       "   'criterion': 'mse'},\n",
       "  {'min_samples_split': 0.3,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'max_leaf_nodes': 10,\n",
       "   'max_depth': 7,\n",
       "   'criterion': 'mae'},\n",
       "  {'min_samples_split': 0.3,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'max_leaf_nodes': 2,\n",
       "   'max_depth': 7,\n",
       "   'criterion': 'mae'},\n",
       "  {'min_samples_split': 0.4,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'max_leaf_nodes': 2,\n",
       "   'max_depth': 7,\n",
       "   'criterion': 'mse'},\n",
       "  {'min_samples_split': 0.7,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'max_leaf_nodes': 10,\n",
       "   'max_depth': 3,\n",
       "   'criterion': 'mse'},\n",
       "  {'min_samples_split': 0.9,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'max_leaf_nodes': 2,\n",
       "   'max_depth': 7,\n",
       "   'criterion': 'mse'},\n",
       "  {'min_samples_split': 0.1,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'max_leaf_nodes': 2,\n",
       "   'max_depth': 7,\n",
       "   'criterion': 'mse'},\n",
       "  {'min_samples_split': 0.4,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'max_leaf_nodes': 10,\n",
       "   'max_depth': 5,\n",
       "   'criterion': 'mae'},\n",
       "  {'min_samples_split': 0.6,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'max_leaf_nodes': 6,\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'mae'},\n",
       "  {'min_samples_split': 0.3,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'max_leaf_nodes': 6,\n",
       "   'max_depth': 1,\n",
       "   'criterion': 'mse'}],\n",
       " 'split0_test_neg_mean_absolute_error': array([-9.1273458 , -6.82081571, -8.6996747 , -7.18169965, -7.76183782,\n",
       "        -7.70546633, -7.46981784, -9.11557167, -8.236837  , -7.48353717]),\n",
       " 'split1_test_neg_mean_absolute_error': array([-11.59040575, -12.40554695, -14.07646376, -13.31291796,\n",
       "        -14.65413516, -14.61215604, -11.87705827, -13.75886966,\n",
       "        -14.19275071, -11.87190481]),\n",
       " 'split2_test_neg_mean_absolute_error': array([-16.97050731, -15.76101229, -16.97427303, -16.81510026,\n",
       "        -15.72848752, -15.75629416, -15.35357246, -16.58573725,\n",
       "        -16.96745774, -15.05500511]),\n",
       " 'split3_test_neg_mean_absolute_error': array([-11.66056338,  -7.22092197,  -9.15626904, -19.46986909,\n",
       "         -9.34923101,  -9.42038176,  -8.78219036,  -9.16310045,\n",
       "         -9.40193427,  -8.59692252]),\n",
       " 'split4_test_neg_mean_absolute_error': array([-32.23780281, -31.28745666, -32.4008357 , -32.61661712,\n",
       "        -31.63068442, -31.66957035, -35.30247662, -32.71453723,\n",
       "        -32.48641567, -35.13545381]),\n",
       " 'mean_test_neg_mean_absolute_error': array([-16.31732501, -14.69915071, -16.26150325, -17.87924081,\n",
       "        -15.82487519, -15.83277373, -15.75702311, -16.26756325,\n",
       "        -16.25707908, -15.62856468]),\n",
       " 'std_test_neg_mean_absolute_error': array([ 8.36197652,  8.93926317,  8.64206103,  8.43968536,  8.46345163,\n",
       "         8.47905396, 10.14463125,  8.70082877,  8.71177076, 10.1068853 ]),\n",
       " 'rank_test_neg_mean_absolute_error': array([ 9,  1,  7, 10,  4,  5,  3,  8,  6,  2]),\n",
       " 'split0_test_neg_mean_squared_error': array([-152.30543992,  -99.48591581, -130.62579852, -105.84983986,\n",
       "        -108.54214902, -107.38570666, -119.85791675, -135.32644508,\n",
       "        -124.77939101, -120.14838859]),\n",
       " 'split1_test_neg_mean_squared_error': array([-196.68021159, -207.99047404, -261.36280267, -234.3361558 ,\n",
       "        -273.2915526 , -271.79553083, -196.32791533, -248.45614067,\n",
       "        -265.06908085, -196.2668363 ]),\n",
       " 'split2_test_neg_mean_squared_error': array([-373.99875087, -388.58722132, -371.50454117, -372.40033607,\n",
       "        -485.76159311, -488.47149693, -374.4748922 , -360.70147019,\n",
       "        -367.77421471, -371.62940455]),\n",
       " 'split3_test_neg_mean_squared_error': array([-214.86827133,  -69.81108728, -115.80907278, -435.11863659,\n",
       "        -116.76981591, -118.51371059, -110.74821001, -115.94008147,\n",
       "        -119.50325585, -101.13474698]),\n",
       " 'split4_test_neg_mean_squared_error': array([-3167.92862371, -3027.92756379, -2917.38996313, -3098.95491052,\n",
       "        -3070.01919059, -3074.39514385, -3673.37875458, -2933.71662545,\n",
       "        -2943.09422499, -3657.14721579]),\n",
       " 'mean_test_neg_mean_squared_error': array([-821.15625948, -758.76045245, -759.33843565, -849.33197577,\n",
       "        -810.87686024, -812.11231777, -894.95753777, -758.82815257,\n",
       "        -764.04403348, -889.26531844]),\n",
       " 'std_test_neg_mean_squared_error': array([1175.77270293, 1140.06923577, 1083.05040298, 1130.55962893,\n",
       "        1137.84714301, 1139.50233178, 1392.43482318, 1090.97972176,\n",
       "        1093.46765905, 1387.23139258]),\n",
       " 'rank_test_neg_mean_squared_error': array([ 7,  1,  3,  8,  5,  6, 10,  2,  4,  9])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "params = {'criterion':['mse', 'mae'], 'max_depth':[1, 3, 5, 7], 'max_leaf_nodes':[2, 4, 6, 10], \n",
    "          'min_samples_split':[.1, .2, .3, .4, .5, .6, .7, .8, .9], 'min_samples_leaf':[.1, .2, .3, .4, .5]}\n",
    "rsearch = RandomizedSearchCV(estimator=rf, param_distributions = params, \n",
    "                             scoring=['neg_mean_absolute_error', 'neg_mean_squared_error'], refit='neg_mean_absolute_error')\n",
    "X, y, cols, participants, cut_rows = Xy_prep(model_data, 'target_10', 7, 7)\n",
    "with joblib.parallel_backend('dask'):\n",
    "    rsearch.fit(X, y)\n",
    "rsearch.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micromotion",
   "language": "python",
   "name": "micromotion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
